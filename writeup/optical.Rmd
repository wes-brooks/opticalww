---
title: "Optical properties for sensing contamination"
author: "Wesley Brooks"
output: html_document
---

The goal here is to establish the possibility of using optical properties of water for detecting sewage influence. We use the storm sewer data to train the model.

```{r import-packages, echo=FALSE, message=FALSE, cache=TRUE}
library(dplyr)
library(gbm)

set.seed(11181982)
```




```{r import-data, echo=FALSE, cache=TRUE}
ssum = read.csv("/Users/wrbrooks/git/eem/data/SSSummaryOct222014.csv")
mmsd = read.csv("/Users/wrbrooks/git/eem/data/MMSDSummaryOct222014.csv")
glri = read.csv("/Users/wrbrooks/git/eem/data/GLRISummaryOct222014.csv")
n = nrow(ssum)

#Extract the summary variables:
ssum2 = ssum[,47:ncol(ssum)]
```

There are several possible indicators of sewage in the water samples. Both Lachnobacteria and Bacteroides are human-specific indicators that are measured in the data. We use the sum of the Lachnobacteria and Bacteroides counts as the response variable because they are both indicators of the same contamination process.

Some observations of Lachnobacteria and/or Bacteroides are censored below the limit of detection. Since the GBM software doesn't handle interval-censored data, for now we will impute a value for the censored observations. The imputed value is computed by assuming that the log-transformed counts follow a normal distribution, and imputing for the censored observations the mean of that distribution, conditional on being below the limit of detection. The mean is calculated by rejection sampling from the estimated distribtution of the log-counts.

```{r impute, echo=FALSE, cache=TRUE}
#Assume a Gaussian distribution for log(Lachno.2)
pos.indx.L = which(ssum$Lachno.2 > 225)
mu.Lachno = mean(log(ssum$Lachno.2[pos.indx.L]))
sd.Lachno = sd(log(ssum$Lachno.2[pos.indx.L]))

#compute the mean of the censored Lachno observations via rejection sampling:
propose.L = rnorm(100000, mean=mu.Lachno, sd=sd.Lachno)
mu.cens.L = mean(propose.L[propose.L<log(225)])

#Assume a Gaussian distribution for log(Bachum)
pos.indx.B = which(ssum$Bac.human > 225)
mu.Bachum = mean(log(ssum$Bac.human[pos.indx.B]))
sd.Bachum = sd(log(ssum$Bac.human[pos.indx.B]))

#compute the mean of the censored bacteroides observations via rejection sampling:
propose.B = rnorm(100000, mean=mu.Bachum, sd=sd.Bachum)
mu.cens.B = mean(propose.B[propose.B<log(225)])

#Now impute the censored means for the censored observations:
ssum$Lachno.2[-pos.indx.L] = exp(mu.cens.L)
ssum$Bac.human[-pos.indx.B] = exp(mu.cens.B)

#Create the aggregate response column:
tot = ssum$Lachno.2 + ssum$Bac.human
ssum2$response = tot
```

The data are divided into events for cross-validation. This is preferable to using random CV splits because the observations from a single event are more alike than observations from different events, and we want to measure the ability to measure wastewater influence in future events.


```{r cv, echo=FALSE, cache=TRUE}
models = list()

for (ev in 1:3) {
    #This is temporary, for LOO-CV:
    train = ssum2[ssum$Event!=ev,]
    test = ssum2[ssum$Event==ev,]
    drop = c("!")
    mm = list()
    iter = 0
    
    #Loop through creating models as long as there are variables with no practical influence on the response:
    while(ncol(train) > 2) {
        iter = iter+1
        print(iter)
        
        m = gbm(log10(response) ~., data=train, n.trees=5000, shrinkage=0.005,
                n.minobsinnode=6, interaction.depth=4, cv.folds=nrow(train),
                n.cores=6)
        nt = gbm.perf(m)
        influence = summary(m, n.trees=nt, plotit=FALSE)
        
        drop = as.character(influence$var[influence$rel.inf==0])
        if (length(drop>0))
            influence = influence[-which(as.character(influence$var) %in% drop),]
        nvar = length(influence$var)
        drop = c(drop, as.character(rev(influence$var)[1:(nvar %/% 10)]))
        print(paste("drop: ", length(drop), sep=""))
    
        train = train[,-which(colnames(train) %in% drop)]
    
        print(paste("keep: ", ncol(train) - 1, sep=""))
        mm[[iter]] = m
    }
    
    models[[ev]] = mm    
}
```

Now we need to decide how many variables to use for the best predictions.

Predictions are compared to the observed response in two ways. First is the mean squared error, which measures how well the predicted and observed counts agree. Second, we use a sum of absolute rank differences, which measures how accurately the predictions are sorted from least to greatest.




```{r echo=FALSE}
#For each held-out event, get the model with the lowest PRESS for wastewater influence.
sapply(1:4, function(k) sapply(models[[k]], function(x) (log10(ssum2$response[ssum$Event==k]) - predict(models[[k]][[

cbind(k, log10(ssum2$response[ssum$Event==k]), predict(models[[k]][[which.min(sapply(models[[k]], function(x) abs(length(x$var.names)-15)) )]], ssum2[ssum$Event==k,]))
```



